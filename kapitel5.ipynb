{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risikobasierte Faktoren: Stock Beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hintergrund und Motivation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Basisimplikation des Capital Asset Pricing Modells (CAPM) ist, dass alle Investoren in das Portfolio mit der höchsten erwarteten Überschussrendite pro Risikoeinheit (Sharpe Ratio) investieren und ihre Position in diesem Portfolio entsprechend ihrer Risikopräferenz mit Fremdkapital entweder hebeln (\"leveraging\" - erhöhen) oder enthebeln (\"de-leveraging\" – reduzieren). Viele Anleger, wie z.B. Privatpersonen, Pensionsfonds und Investmentfonds, haben jedoch nur eine eingeschränkte (oder gar keine) Möglichkeiten, Leverage (Fremdkapital) einzusetzen, und müssen daher riskante (High-Beta) Wertpapiere übergewichten, anstatt gehebelte Positionen in Low-Beta Aktien einzugehen. Diese aus Leveragebeschränkungen resultierende Präferenz für High-Beta Aktien kann dazu führen, dass im Gleichgewicht risikoreiche Wertpapiere mit hohem Beta niedrigere risikobereinigte Renditen erfordern als Wertpapiere mit niedrigem Beta, für die eine Hebelwirkung (d.h., eine Position unter Einsatz von Fremdkapital) erforderlich ist. Im Ergebnis bedeutet dies: **Low-Beta gleich High-Alpha**, und **High-Beta gleich Low-Alpha!** (Alpha bezeichnet hier risikoadjustierte Renditen)\n",
    "\n",
    "Tatsächlich ist die Wertpapiermarktlinie für US-Aktien im Vergleich zum CAPM zu flach (Black, Jensen und Scholes, 1972) und lässt sich durch das CAPM mit eingeschränkter Kreditaufnahme besser erklären als durch das Standard-CAPM (siehe schon Black, 1972).\n",
    "\n",
    "In einem viel zitierten Aufsatz stellen Frazzini und Pedersen (FP) (\"Betting against beta\", Journal of Financial Economics, 2014, p. 1-25) eine \"Long minus Short\" Faktorstrategie vor, mit dem Ziel die oben skizzierte **Beta Anomalie** auszunutzen. Sie konstruieren dabei einen \"Betting Against Beta\" (BAB) Faktor, der im Kern Low-Beta Aktien übergewichtet und High-Beta Aktien untergewichtet. Sie wenden die Faktorkonstruktion auf zahlreiche Assetklassen (US und 20 internationale Aktienmärkte, US-Staatsanleihen und Unternehmensanleihen, Future Märkte) an und können zeigen, dass die Faktorstrategie überall persistente, positive risikoadjustierte Renditen erwirtschaftet.  \n",
    "\n",
    "Im folgenden implementieren wir die Basisversion der FP BAB Faktorstrategie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginn der Fallstudie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beginnen mit dem Laden der notwendigen Pakete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir setzen die BAB Faktorstrategie am Beispiel des S&P500 Universums um. Zunächst laden wir zwei Datensätze in Form von DataFrames, eines für die täglichen Aktienkurshistorien der S&P500 Mitglieder und eines für die Zeitreihe der Indexwerte des S&P500. Wir mergen beide Datensätze in dem DataFrame `joined_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galina\\Documents\\Thomas\\Python Projekte\\examplefiles\n"
     ]
    }
   ],
   "source": [
    "# load of data: df with S&P500 constituents and df with S&P500 index values\n",
    "%cd \"C:\\Users\\Galina\\Documents\\Thomas\\Python Projekte\\examplefiles\"\n",
    "constituents = pd.read_csv('s&p_500_15112019.csv', \n",
    "                   parse_dates=True, index_col=0)\n",
    "index = pd.read_csv('s&p_500_012000_102019.csv',parse_dates=True, index_col=0) \n",
    "sp_index = index['Adj Close']\n",
    "sp_index.name = 'SP_Index'\n",
    "\n",
    "# adjustment for different frequency of constituents and index\n",
    "joined_df = pd.merge(constituents, sp_index, how='inner', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>AMG</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>SP_Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>36.866280</td>\n",
       "      <td>54.056015</td>\n",
       "      <td>112.360001</td>\n",
       "      <td>110.738106</td>\n",
       "      <td>35.941536</td>\n",
       "      <td>103.480003</td>\n",
       "      <td>11.43</td>\n",
       "      <td>169.755737</td>\n",
       "      <td>10.266887</td>\n",
       "      <td>141.927734</td>\n",
       "      <td>...</td>\n",
       "      <td>81.712685</td>\n",
       "      <td>37.324787</td>\n",
       "      <td>25.328613</td>\n",
       "      <td>55.914982</td>\n",
       "      <td>47.835201</td>\n",
       "      <td>60.320660</td>\n",
       "      <td>101.052895</td>\n",
       "      <td>40.778381</td>\n",
       "      <td>52.556099</td>\n",
       "      <td>2257.830078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>37.158947</td>\n",
       "      <td>54.818222</td>\n",
       "      <td>115.739998</td>\n",
       "      <td>111.004356</td>\n",
       "      <td>36.647812</td>\n",
       "      <td>104.139999</td>\n",
       "      <td>11.43</td>\n",
       "      <td>171.148819</td>\n",
       "      <td>10.178833</td>\n",
       "      <td>145.451904</td>\n",
       "      <td>...</td>\n",
       "      <td>84.347366</td>\n",
       "      <td>37.490185</td>\n",
       "      <td>26.284410</td>\n",
       "      <td>55.507954</td>\n",
       "      <td>48.548149</td>\n",
       "      <td>60.540157</td>\n",
       "      <td>101.981964</td>\n",
       "      <td>41.363899</td>\n",
       "      <td>53.066067</td>\n",
       "      <td>2270.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>37.479931</td>\n",
       "      <td>55.233967</td>\n",
       "      <td>114.809998</td>\n",
       "      <td>109.340340</td>\n",
       "      <td>37.216755</td>\n",
       "      <td>105.910004</td>\n",
       "      <td>11.24</td>\n",
       "      <td>171.029388</td>\n",
       "      <td>10.046756</td>\n",
       "      <td>143.670349</td>\n",
       "      <td>...</td>\n",
       "      <td>85.431145</td>\n",
       "      <td>37.490185</td>\n",
       "      <td>26.174128</td>\n",
       "      <td>54.835869</td>\n",
       "      <td>48.104961</td>\n",
       "      <td>60.740559</td>\n",
       "      <td>102.637207</td>\n",
       "      <td>40.693394</td>\n",
       "      <td>52.889545</td>\n",
       "      <td>2269.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>38.499535</td>\n",
       "      <td>55.251297</td>\n",
       "      <td>115.419998</td>\n",
       "      <td>110.585968</td>\n",
       "      <td>37.187328</td>\n",
       "      <td>108.300003</td>\n",
       "      <td>11.32</td>\n",
       "      <td>168.790543</td>\n",
       "      <td>10.407769</td>\n",
       "      <td>143.349106</td>\n",
       "      <td>...</td>\n",
       "      <td>86.356071</td>\n",
       "      <td>37.600452</td>\n",
       "      <td>25.769753</td>\n",
       "      <td>55.896046</td>\n",
       "      <td>47.767757</td>\n",
       "      <td>61.475353</td>\n",
       "      <td>102.646980</td>\n",
       "      <td>40.957817</td>\n",
       "      <td>53.056259</td>\n",
       "      <td>2276.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>38.461781</td>\n",
       "      <td>55.615067</td>\n",
       "      <td>117.110001</td>\n",
       "      <td>109.349854</td>\n",
       "      <td>36.981331</td>\n",
       "      <td>108.570000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>168.691055</td>\n",
       "      <td>10.152417</td>\n",
       "      <td>139.630264</td>\n",
       "      <td>...</td>\n",
       "      <td>86.655045</td>\n",
       "      <td>37.030743</td>\n",
       "      <td>25.622707</td>\n",
       "      <td>55.905521</td>\n",
       "      <td>47.565422</td>\n",
       "      <td>61.647121</td>\n",
       "      <td>104.642014</td>\n",
       "      <td>40.513969</td>\n",
       "      <td>52.909161</td>\n",
       "      <td>2268.899902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ABT       ABBV        ABMD         ACN       ATVI  \\\n",
       "Date                                                                  \n",
       "2017-01-03  36.866280  54.056015  112.360001  110.738106  35.941536   \n",
       "2017-01-04  37.158947  54.818222  115.739998  111.004356  36.647812   \n",
       "2017-01-05  37.479931  55.233967  114.809998  109.340340  37.216755   \n",
       "2017-01-06  38.499535  55.251297  115.419998  110.585968  37.187328   \n",
       "2017-01-09  38.461781  55.615067  117.110001  109.349854  36.981331   \n",
       "\n",
       "                  ADBE    AMD         AAP        AES         AMG  ...  \\\n",
       "Date                                                              ...   \n",
       "2017-01-03  103.480003  11.43  169.755737  10.266887  141.927734  ...   \n",
       "2017-01-04  104.139999  11.43  171.148819  10.178833  145.451904  ...   \n",
       "2017-01-05  105.910004  11.24  171.029388  10.046756  143.670349  ...   \n",
       "2017-01-06  108.300003  11.32  168.790543  10.407769  143.349106  ...   \n",
       "2017-01-09  108.570000  11.49  168.691055  10.152417  139.630264  ...   \n",
       "\n",
       "                 WYNN        XEL        XRX       XLNX        XYL        YUM  \\\n",
       "Date                                                                           \n",
       "2017-01-03  81.712685  37.324787  25.328613  55.914982  47.835201  60.320660   \n",
       "2017-01-04  84.347366  37.490185  26.284410  55.507954  48.548149  60.540157   \n",
       "2017-01-05  85.431145  37.490185  26.174128  54.835869  48.104961  60.740559   \n",
       "2017-01-06  86.356071  37.600452  25.769753  55.896046  47.767757  61.475353   \n",
       "2017-01-09  86.655045  37.030743  25.622707  55.905521  47.565422  61.647121   \n",
       "\n",
       "                   ZBH       ZION        ZTS     SP_Index  \n",
       "Date                                                       \n",
       "2017-01-03  101.052895  40.778381  52.556099  2257.830078  \n",
       "2017-01-04  101.981964  41.363899  53.066067  2270.750000  \n",
       "2017-01-05  102.637207  40.693394  52.889545  2269.000000  \n",
       "2017-01-06  102.646980  40.957817  53.056259  2276.979980  \n",
       "2017-01-09  104.642014  40.513969  52.909161  2268.899902  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden in drei Schritten die BAB Faktorstrategie von FP implementieren. Zunächst schreiben wir eine Funktion (*calc_beta*), die den renditeprognostizierenden Faktor (das Aktienbeta zum Marktindex) für jede Aktie täglich auf Basis rollierender Zeitfenster berechnet. Danach verwenden wir diesen Faktor in der Funktion *bab_weights* um zwei Faktorportfolios zu bilden. Das Long (Low-Beta) Portfolio enthält Aktien mit niedrigem Beta, und das Short (High-Beta) Portfolio beinhaltet die Aktien, die stärker mit dem Markt variieren. In der dritten Funktion *bab_strat* führen wir alles zusammen, konstruieren den BAB \"Long minus Short\" Faktor, wobei die beiden Portfolios jeweils mit der Inversen ihres Betas skaliert werden, und berechnen für eine gegebene Halteperiode die annualisierte Sharpe-Ratio der Faktorstrategie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex Ante Betas als Faktor\n",
    "Das geschätze $\\beta$ für Aktie $i$ ist definiert durch (siehe FP, 2014, Gleichung 14): \n",
    "\n",
    "$$\\beta^{TS}_{i}=\\rho\\frac{\\sigma_{i}}{\\sigma_{m}}$$\n",
    "\n",
    "Hierbei sind $\\sigma_{i}$ und $\\sigma_{m}$ die historisch geschätzen Renditevolatilitäten der Aktie $i$ und des Marktes und $\\rho$ deren geschätzte Korrelation. FP schätzen Volatilitäten und Korrelationen separat. Konkret verwenden sie 1-Tages Log-Renditen für Volatilitäten und überlappende 3-Tages Log-Renditen für Korrelationen. Die jeweiligen gleitenden Zeitfenster für die täglichen rollierenden Schätzungen betragen 1 Jahr bei Volatilitäten und 5 Jahre für Korrelationen. \n",
    "\n",
    "Um den Einfluss von Ausreißern zu mindern werden die obigen (täglichen) Zeitreihen-Betas $\\beta^{TS}_{i}$ in Richtung des Querschnittsmittelwertes $\\beta^{XS}$ über folgende Gleichung geschrumpft (sogenannte \"Shrinkage\"-Schätzung; siehe FP, 2014, Gleichung 15):\n",
    "\n",
    "$$\\beta_{i}=w_{i}\\beta^{TS}_{i}+(1-w_{i})\\beta^{XS}$$\n",
    "\n",
    "Zur Vereinfachung setzen FP $w=0.6$ und $\\beta^{XS}=1$ für alle Zeitpunkte und Wertpapiere. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir implementieren die Berechnung der FP Betas in der Funktion `calc_beta`. Diese benötigt als Eingabe ein DataFrame mit täglichen Historien an Aktienkursen und Marktindexwerten. Über `apply(lambda...)` erstellen wir jeweils DataFrames mit täglichen Zeitreihen von 1-Tages und überlappenden (kumulativen) 3-Tages Log-Renditen. Diese DataFrames werden über die `rolling`-Funktionalität transformiert in DataFrames mit Standardabweichungen (*stdev*), dem Verhältnis der Aktienvolatilität zur Marktvolatilität (*stdev_ratio*), und Renditekorrelationen (*corr*) mit dem Marktindex (Spalte 'SP_Index'). Die Zeitreihenbetas $\\beta^{TS}_{i}$ ergeben sich aus der zellenweisen Multiplikation von *corr* und *stdev_ratio*. Die geschrumpften Betas $\\beta_{i}$ sind im finalen DataFrame `beta_shrink` enthalten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of Frazzini and Pedersen (2014) beta (equations (14) and (15))\n",
    "def calc_beta(joined_df):\n",
    "    joined_df = joined_df.asfreq('B').fillna(method='pad')\n",
    "    # calculation of log-returns (1 day and 3 days-overlapping)\n",
    "    log1_rets = joined_df.apply(lambda x: np.log(x/x.shift(1)))\n",
    "    log3_rets = joined_df.apply(lambda x: np.log(x/x.shift(3)))\n",
    "\n",
    "    # individual calculation of volas, correlation and finally betas\n",
    "    stdev = log1_rets.rolling(250, min_periods=120).std()\n",
    "    stdev_ratio = stdev.div(stdev['SP_Index'], axis=0)\n",
    "    corr = log3_rets.rolling(250, min_periods=120).corr(log3_rets['SP_Index'])\n",
    "    beta = np.multiply(corr, stdev_ratio)\n",
    "    beta_shrink = 0.6 * beta + 0.4\n",
    "    return beta_shrink\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konstruktion der Long-/Short-Portfolios\n",
    "\n",
    "Um ihren BAB-Faktor zu konstruieren, ordnen FP alle Wertpapiere im Datensatz zu jedem Zeitpunkt in aufsteigender Reihenfolge auf Grundlage der geschätzten Betas an (Perzentil-Ranking). Die geordneten Wertpapiere werden einem von zwei Portfolios zugewiesen: dem Low-Beta ($L$) und dem High-Beta ($H$) Portfolio. Der FP BAB Faktor basiert darauf, Long in das Low-Beta und Short in das High-Beta Portfolio zu gehen. Das Low- (High-) Beta Portfolio setzt sich aus allen Aktien zusammen, deren Beta unter (über) dem Median-Beta aller Wertpapiere im Datensatz liegt. In jedem Portfolio werden Wertpapiere anhand des Perzentil-Rangs ihres geschätzten Betas gewichtet. D.h., im Low-Beta Portfolio haben Wertpapiere mit niedrigerem Beta größere Gewichte, und im High-Beta Portfolio steigt entsprechend das Gewicht für Wertpapiere mit höherem Beta. Formal ergeben sich die Gewichtsvektoren der Aktien in beiden Portfolios wie folgt (siehe FP, 2014, Gleichung 16):\n",
    "\n",
    "$$w_{H}=k(z-\\mu_{z})^+$$\n",
    "$$w_{L}=k(z-\\mu_{z})^-$$\n",
    "\n",
    "Hierbei bezeichnet $z$ einen $n x 1$ Vektor der Beta-Perzentil-Ränge $z_{i}=rank(\\beta_{it})$ zum Zeitpunkt der Portfoliokonstruktion, $\\mu_{z}=1_{n}z/n$ den durchschnittlichen Rang, $n$ die Anzahl der Aktien und $1_{n}$ den Einheitsvektor der Dimension $n x 1$. $x^+$ und $x^-$ kennzeichnen die positiven bzw. negativen Elemente eines Vektors $x$. Um sicher zu stellen, dass sich die Gewichte in beiden Portfolios zu 1 summieren, d.h., $1_{n}w_{H}=1$ bzw. $1_{n}w_{L}=1$ gilt, wird die Normalisierungskonstante $k$ definiert als $k=2/1_{n}|z-\\mu_{z}|$. \n",
    "\n",
    "In Worten ergibt sich das Gewicht jeder Aktie aus der Rangabweichung der Aktie vom mittleren Rang skaliert mit der (d.h. geteilt durch die) Hälfte der Summe der absoluten Rangabweichungen über alle Aktien. \n",
    "\n",
    "Zur Implementierung der FP Portfolios verwenden wir das tägliche DataFrame `ranks` mit den Perzentil-Rängen der Aktien gemäß ihres geschätzten Betas. Daraus erstellen wir ein neues DataFrame `demeaned` mit Rangabweichungen indem wir jeweils den Zeilenmittelwert (`ranks.mean(axis=1)`) der Ränge vom Rang einer Aktie abziehen. \n",
    "\n",
    "Im nächsten Schritt generieren wir zwei transformierte Versionen von `demeaned`, die DataFrames `long` und `short`, mit Indikatoren (0/1-Variablen), die jeweils anzeigen, ob eine Aktie an einen entsprechenden Tag in das Long (High-Beta) oder das Short (Low-Beta) Portfolio gehört. \n",
    "\n",
    "Dann erstellen wir das DataFrame `abs_demeaned` mit den absoluten Rangabweichungen. Wir bekommen die normalisierten Gewichte (DataFrame `weights`) indem wir die Zeilenwerte von `abs_demeaned` durch die Hälfte der korrespondierenden Zeilensumme von `abs_demeaned` teilen. \n",
    "\n",
    "Wir erhalten die beiden DataFrames `long_weights` und `short_weights` mit den täglichen Zeitreihen der Portfoliogewichtsvektoren indem wir das DataFrame `weights` jeweils mit den DataFrames der Portfolio-Positionsindikatoren multiplizieren.\n",
    "\n",
    "Im letzten Schritt berechnen wir die Zeitreihe der beiden Portfolio-Betas durch zellenweise Multiplikation des DataFrames der Aktienbeta-Zeitreihen (`beta`) mit den DataFrames der Portfoliogewichte und Bilden der Zeilensummen. \n",
    "\n",
    "Fassen wir diese Schritte nun in der Gewichtsfunktion `bab_weights` zusammen. Diese Funktion benötigt als Eingabe ein DataFrame mit Aktienkurshistorien und Indexwerten. Als Ausgabe der Funktion erhalten wir die beiden DataFrames mit den Portfoliogewichten zu jedem Zeitpunkt, und zwei Zeitreihen mit den gewichteten Betas der Portfolios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of weights, equation (16) in Frazzini and Pedersen (2014)\n",
    "def bab_weights(joined_df):\n",
    "    beta_shrink = calc_beta(joined_df)\n",
    "    beta_shrink = beta_shrink.dropna(thresh=10) # min 10 obs each row with non-missing betas\n",
    "    beta = beta_shrink.drop('SP_Index', axis=1)\n",
    "    ranks = beta.rank(ascending=True, axis=1, pct=True) # percentile ranks\n",
    "    demeaned = ranks.sub(ranks.mean(axis=1), axis='index') # cross-sectional demeaned\n",
    "\n",
    "    # indicator matrix: 1 for long position (demeaned beta negativ)\n",
    "    long = demeaned.copy()\n",
    "    for col in long.columns:\n",
    "        long[col] = np.where(long[col]<0, 1, 0)\n",
    "    \n",
    "    #indicator matrix: 1 for short position (demeaned beta positiv)\n",
    "    short = demeaned.copy()\n",
    "    for col in short.columns:\n",
    "        short[col] = np.where(short[col]>0, 1, 0)\n",
    "    \n",
    "    # calculation of normalized weights    \n",
    "    abs_demeaned = abs(demeaned) \n",
    "    # demeaned percentile ranks normalized by 0.5 * cross-sectional sum of abs. demeaned weights\n",
    "    weights = abs_demeaned.div(0.5 * abs_demeaned.sum(axis=1), axis='index')\n",
    "\n",
    "    # separate matrix for long and short weights\n",
    "    long_weights = np.multiply(long, weights)\n",
    "    short_weights = np.multiply(short, weights)\n",
    "\n",
    "    # calculation of long and short portfolio betas\n",
    "    long_beta = (beta * long_weights).sum(axis=1)\n",
    "    short_beta = (beta * short_weights).sum(axis=1)\n",
    "    return long_weights, short_weights, long_beta, short_beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit dem dritten Schritt, der Konstruktion des BAB Faktors, weitermachen, definieren wir unsere bekannten **Lambda** Hilfs-Funktionen:\n",
    "    \n",
    "    1. \"compound\" berechnet aus dem Eingabe-Array x kumulative Mehr-Tagesrenditen;\n",
    "    2. \"daily_sr\" berechnet aus einem Array von Tagesrenditen die tägliche Sharpe-Ratio;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative returns\n",
    "compound = lambda x: (1 + x).prod() - 1\n",
    "\n",
    "# daily sharpe ratio\n",
    "daily_sr = lambda x: x.mean() / x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konstruktion des BAB Faktors\n",
    "\n",
    "Konstruktionsbedingt ist das Portfoliobeta im Long (Low-Beta) Portfolio immer kleiner als das im Short (High-Beta) Portfolio. Wie lässt sich nun eine Long-Short BAB Faktorstrategie implementieren, die marktneutral (Zero-Beta Portfolio) ist? Hierzu müssen die Positionen in den beiden Portfolios gehebelt werden. Konkret benötigen wir eine \"leveraged\" Position im Low-Beta Portfolio und eine \"deleveraged\" Position im High-Beta Portfolio. Das Ziel ist es hierbei, dass die Positionen in den beiden Portfolios jeweils ein Beta von Eins haben. Hat das $L$ ($H$) Portfolio beispielsweise ein Beta von 0,75 (1,4), müssen 1,33 (0,7) Geldeinheiten in das Portfolio investiert werden. Die Finanzierung der Positionen erfolgt dabei über entsprechend entgegengesetzte Positionen im risikolosen Zins um die Strategie selbstfinanzierend zu halten. **Wichtig:** Eine Geldeinheit Long und eine Geldeinheit Short führen nicht zu einem Zero-Beta Faktor! Formal ergibt sich die BAB Faktorstrategierendite folglich als (siehe FP, 2014, Gleichung 17):\n",
    "\n",
    "$$r^{BAB}_{t+1}=\\frac{1}{\\beta^L_{t}}(r^L_{t+1}-r_{f})-\\frac{1}{\\beta^H_{t}}(r^H_{t+1}-r_{f}),$$\n",
    "\n",
    "mit $r^L_{t+1}=r^´_{t+1}w_{L}$, $r^H_{t+1}=r^´_{t+1}w_{H}$, $\\beta^L_{t}=\\beta^´_{t}w_{L}$, und $\\beta^H_{t}=\\beta^´_{t}w_{H}$. Im folgenden unterstellen wir zur Vereinfachung einen risikolosen Zins $r_{f}$ von Null. \n",
    "\n",
    "Wir implementieren nun die Konstruktion der marktneutralen BAB Faktorstrategie in der Funktion `bab_strat`. Wie immer halten wir das Faktorportfolio konstant für eine Anzahl von Handelstagen, die durch das Argument *hold* angegeben wird. \n",
    "\n",
    "**Wichtig:** Wir reduzieren die Zeitfrequenz der DataFrames mit den täglichen (Long/Short) Portfoliogewichtsvektoren und der Zeitreihen der Portfoliobetas auf die Länge (*hold*) der gewählten Portfoliohalteperiode, setzen die Gewichte/Betas auf die Werte die zu Beginn der Halteperiode gelten (über `.first()`), und wählen `.shift(1)`, da in t nur die Gewichte die zum Zeitpunkt t-1 bekannt sind implementiert werden können.  \n",
    "\n",
    "Wir berechnen separate Zeitreihen der kumulierten Halteperioderenditen für das Long- und das Short-Portfolio (*long_rets* bzw. *short_rets*). Die Faktorrendite ergibt sich als Differenz (Long minus Short) der Portfoliorenditen, jeweils skaliert mit der Inversen des Portfoliobetas.\n",
    "\n",
    "Zusätzlich zur annualisierten Sharpe-Ratio der Strategie gibt uns die Funktion auch die Sharpe-Ratio der Benchmark, d.h., der S&P500 Indexrenditen, zurück. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of bab factor and strategy returns:\n",
    "# equation (17) in Frazzini and Pedersen (2014)\n",
    "def bab_strat(joined_df, hold):\n",
    "    freq = '%dB' % hold # holding period in number of business days\n",
    "    # weights and portfolio betas for each business day\n",
    "    long_weights, short_weights, long_beta, short_beta = bab_weights(joined_df)\n",
    "\n",
    "    # daily returns\n",
    "    daily_rets = joined_df.pct_change()\n",
    "    long_beta.name ='long_beta'  \n",
    "    # adjustment of frequency for returns and beta/weights time series\n",
    "    daily_rets = pd.merge(daily_rets, long_beta, how='inner', on='Date').drop('long_beta', axis=1)\n",
    "    \n",
    "    # calculation of benchmark sharpe ratio\n",
    "    bench_rets = daily_rets['SP_Index']\n",
    "    bench_sharpe = daily_sr(bench_rets) * np.sqrt(252)\n",
    "    daily_rets = daily_rets.drop('SP_Index', axis=1)\n",
    "    \n",
    "    # taking weights and betas from the beginning of the holding period\n",
    "    long_weights = long_weights.shift(1).resample(freq).first() # time series with holding period freq\n",
    "    long_beta = long_beta.shift(1).resample(freq).first() # time series with holding period freq\n",
    "    short_weights = short_weights.shift(1).resample(freq).first() # time series with holding period freq\n",
    "    short_beta = short_beta.shift(1).resample(freq).first() # time series with holding period freq\n",
    "\n",
    "    # calculating holding period returns for long and short portfolio\n",
    "    returns = daily_rets.resample(freq).apply(compound)\n",
    "    long_rets = (long_weights * returns).sum(axis=1) # weighted sum of security returns \n",
    "    short_rets = (short_weights * returns).sum(axis=1) # weighted sum of security returns \n",
    "\n",
    "    # finally, calculating strategy returns (equation (17))\n",
    "    bab_rets = (1/long_beta * long_rets) - (1/short_beta * short_rets)\n",
    "    bab_sharpe = daily_sr(bab_rets) * np.sqrt(252/hold)\n",
    "    \n",
    "    return bab_sharpe, bench_sharpe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen wir nun die Sharpe-Ratios der BAB Strategie mit einer Rebalancingfrequenz von 20 Tagen und der passiven Benchmark (S&P500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9439961839745289, 0.7395384250144774)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bab_strat(joined_df, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
