{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risikobasierte Faktoren: Idiosyncratic Volatility - IVOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hintergrund und Motivation\n",
    "Das CAPM impliziert, dass das Gesamtrisiko (Renditevarianz) eines Wertpapiers aus zwei Summanden besteht, von denen der erste Summand die Renditeschwankungen des Marktes und der zweite Summand die wertpapierspezifischen Renditeschwankungen beinhaltet. \n",
    "\n",
    "$$Var(R_{i,t}) = \\beta^{2}_{i} Var(R_{m,t}) + Var(\\epsilon_{i})$$\n",
    "\n",
    "$\\epsilon_{i}$ kennzeichnet dabei die Renditeresiduen des Wertpapiers $i$, und $Var(\\epsilon_{i})$ wird auch als idiosynkratische Varianz (unsystematisches Risiko) bezeichnet. Die Wurzel daraus ist die idiosynkratische Volatilität (IVOL). Verallgemeinert man den obigen Zusammenhang wird offensichtlich, dass sich IVOL auf Basis unterschiedlicher (Ein-) oder Mehrfaktormodelle berechnen läßt, immer als realisierte (empirische) Standardabweichung der sich aus der Faktorregression ergebenden Renditeresiduen. \n",
    "\n",
    "In zwei einflussreichen Arbeiten dokumentieren Ang, Hodrick, Xing und Zhang (2006, 2009) einen negativen Zusammenhang zwischen der idiosynkratischen Volatilität und zukünftigen Aktienrenditen. In dem Maße, in dem die realisierte idiosynkratische Volatilität für die erwartete idiosynkratische Volatilität steht, ist dieses Ergebnis unerwartet (ein „Puzzle“), da traditionelle Asset-Pricing-Theorien (z.B. das CAPM) entweder keinen Zusammenhang zwischen der erwarteten idiosynkratischen Volatilität und erwarteten Renditen vorhersagen wenn Märkte vollständig und friktionslos sind und Anleger sich gut diversifizieren können, oder eine positive Beziehung prognostizieren unter der Annahme, dass Märkte unvollständig und mit Friktionen behaftet sind und Anleger schlecht diversifizierte Portfolios halten. \n",
    "\n",
    "Eine bekannte Form der **Low Risk Anomaly** ist folglich das **Idiosyncratic Volatility Puzzle (IVP)**. Hou und Loh (2016) untersuchen empirisch zahlreiche Erklärungsansätze für die Existenz des IVP. \n",
    "\n",
    "Wir werden im folgenden eine Faktorstrategie mit IVOL als renditeprognostizierenden Faktor implementieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginn der Fallstudie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beginnen mit dem Laden der notwendigen Pakete. Zur Durchführung von OLS Regressionen (mit einer Konstanten) importieren wir die Module `linear_model` und `tools`aus dem Paket `statsmodels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.regression.linear_model as sm\n",
    "import statsmodels.tools.tools as sm2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir setzen die IVOL Faktorstrategie am Beispiel des S&P500 Universums um. Zunächst laden wir zwei Datensätze in Form von DataFrames, eines für die täglichen Aktienkurshistorien der S&P500 Mitglieder und eines für die Zeitreihe der Indexwerte des S&P500. Wir mergen beide Datensätze in dem DataFrame `joined_df` und berechnen diskrete Tagesrenditen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Galina\\Documents\\Thomas\\Python Projekte\\examplefiles\n"
     ]
    }
   ],
   "source": [
    "# load of data: df with S&P500 constituents and df with S&P500 index values\n",
    "%cd \"C:\\Users\\Galina\\Documents\\Thomas\\Python Projekte\\examplefiles\"\n",
    "constituents = pd.read_csv('s&p_500_15112019.csv', \n",
    "                   parse_dates=True, index_col=0)\n",
    "index = pd.read_csv('s&p_500_012000_102019.csv',parse_dates=True, index_col=0) \n",
    "sp_index = index['Adj Close']\n",
    "sp_index.name = 'SP_Index'\n",
    "\n",
    "# adjustment for different frequency of constituents and index\n",
    "joined_df = pd.merge(constituents, sp_index, how='inner', on='Date')\n",
    "df_returns = joined_df.pct_change().dropna(how='all')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>AMG</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>SP_Index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>-0.008576</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032243</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>-0.007279</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.014359</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.005722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.007584</td>\n",
       "      <td>-0.008035</td>\n",
       "      <td>-0.014991</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.016996</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.012976</td>\n",
       "      <td>-0.012248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004196</td>\n",
       "      <td>-0.012108</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>-0.016210</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.000771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>0.027204</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>0.022566</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>-0.013090</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>-0.015449</td>\n",
       "      <td>0.019334</td>\n",
       "      <td>-0.007010</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>-0.000981</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>-0.011178</td>\n",
       "      <td>-0.005539</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.015018</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>-0.024535</td>\n",
       "      <td>-0.025943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>-0.005706</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.004236</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>-0.010837</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>-0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>0.013500</td>\n",
       "      <td>-0.002180</td>\n",
       "      <td>-0.041585</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>-0.002855</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>-0.017346</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ABT      ABBV      ABMD       ACN      ATVI      ADBE  \\\n",
       "Date                                                                     \n",
       "2017-01-04  0.007939  0.014100  0.030082  0.002404  0.019651  0.006378   \n",
       "2017-01-05  0.008638  0.007584 -0.008035 -0.014991  0.015525  0.016996   \n",
       "2017-01-06  0.027204  0.000314  0.005313  0.011392 -0.000791  0.022566   \n",
       "2017-01-09 -0.000981  0.006584  0.014642 -0.011178 -0.005539  0.002493   \n",
       "2017-01-10  0.013500 -0.002180 -0.041585  0.000522  0.018037 -0.002855   \n",
       "\n",
       "                 AMD       AAP       AES       AMG  ...      WYNN       XEL  \\\n",
       "Date                                                ...                       \n",
       "2017-01-04  0.000000  0.008206 -0.008576  0.024831  ...  0.032243  0.004431   \n",
       "2017-01-05 -0.016623 -0.000698 -0.012976 -0.012248  ...  0.012849  0.000000   \n",
       "2017-01-06  0.007117 -0.013090  0.035933 -0.002236  ...  0.010827  0.002941   \n",
       "2017-01-09  0.015018 -0.000589 -0.024535 -0.025943  ...  0.003462 -0.015152   \n",
       "2017-01-10 -0.004352  0.002300 -0.017346 -0.001116  ...  0.022426 -0.000248   \n",
       "\n",
       "                 XRX      XLNX       XYL       YUM       ZBH      ZION  \\\n",
       "Date                                                                     \n",
       "2017-01-04  0.037736 -0.007279  0.014904  0.003639  0.009194  0.014359   \n",
       "2017-01-05 -0.004196 -0.012108 -0.009129  0.003310  0.006425 -0.016210   \n",
       "2017-01-06 -0.015449  0.019334 -0.007010  0.012097  0.000095  0.006498   \n",
       "2017-01-09 -0.005706  0.000170 -0.004236  0.002794  0.019436 -0.010837   \n",
       "2017-01-10  0.008608 -0.008974 -0.004658  0.005883  0.062337  0.015384   \n",
       "\n",
       "                 ZTS  SP_Index  \n",
       "Date                            \n",
       "2017-01-04  0.009703  0.005722  \n",
       "2017-01-05 -0.003326 -0.000771  \n",
       "2017-01-06  0.003152  0.003517  \n",
       "2017-01-09 -0.002773 -0.003549  \n",
       "2017-01-10 -0.000371  0.000000  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_returns.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IVOL als Faktor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir berechnen die IVOL einer Aktie auf Basis eines Einfaktor-Modells (*Single-Index Model*), wobei die S&P Indexrendite den (Markt-) Faktor darstellt. Durch die Regression von Aktienrenditen auf die Indexrendite erhalten wir Residuen, deren Streuung (Standardabweichung) die idiosynkratische Volatilität (IVOL) einer Aktie symbolisiert. Wir berechnen die IVOL täglich auf Basis eines rollierenden Zeitfensters dessen Länge wir mit dem Argument `window` festlegen.\n",
    "\n",
    "Lassen Sie uns zunächst eine Funktion `idiovola_single()` schreiben, die die rollierende IVOL für eine einzelne Aktie berechnet. Das Argument `col` bezeichnet hierbei die Historie der täglichen Aktienrenditen (y-Variable der Regression) und die Spalte 'SP_Index' des DataFrames `df_returns` enthält die x-Variable (Indexrenditen). **Wichtig:** Wollen wir IVOLs auf Basis von Multifaktoren-Modellen (z.B. dem Fama/French 3-Faktor Modell oder Erweiterungen hiervon) berechnen, muss `df_returns` entsprechende Zeitreihen der Faktorrenditen enthalten. \n",
    "\n",
    "Über die Funktion `add_constant` fügen wir zum Vektor der Indexrenditen einen gleichlangen Vektor mit \"Einsen\", die den Achsenabschnitt (Konstante der Regression) representieren, hinzu. \n",
    "\n",
    "Für jedes Zeitfenster der Länge `window` (von iStart bis iEnd) führen wir über `sm.OLS(y-Variable, (Konstante, x-Variable)).fit()` eine OLS Regression durch, berechnen die Standardabweichung der sich ergebenden Residuen (std_resids = IVOL) und speichern alle IVOLs in der Liste `empty_list`.\n",
    "\n",
    "Diese Liste wird anschließend in ein einspaltiges DataFrame `idio_vola` transformiert, wobei der Zeilenindex den Zeitpunkten (`df_new['Date']`) entspricht, für die jeweils die täglichen rollierenden IVOLs berechnet wurden. **Beachten:** Durch `reset_index('Date')` wird der Zeilenindex 'Date' des DataFrames `df_returns` in eine normale Spalte transformiert, die dann wiederum über `pd.concat()` mit Spalten anderer DataFrames verkettet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate rolling IVOL for a df of stock and factor returns\n",
    "# first a function for a single stock\n",
    "def idiovola_single(col, df_returns, window=250):\n",
    "    # col =y-variable; df_returns.SP_Index = x-variable\n",
    "    x1 = df_returns.SP_Index # adjustment necessary for multi-factors!\n",
    "    x2 = sm2.add_constant(x1)\n",
    "    empty_list = list()\n",
    "    # rolling window:[iStart,iEnd]\n",
    "    for iStart in range(0, len(df_returns)-window):\n",
    "        iEnd = iStart+window        \n",
    "        # Calculate regression residuals std\n",
    "        reg = sm.OLS(col[iStart:iEnd],x2[iStart:iEnd]).fit()\n",
    "        std_resids = np.std(reg.resid)\n",
    "        empty_list.append(std_resids)\n",
    "\n",
    "    idio_vola0 = pd.DataFrame(empty_list)\n",
    "    df_new = df_returns[window:len(df_returns)].reset_index('Date')\n",
    "    idio_vola = pd.concat([df_new['Date'], idio_vola0], axis=1)\n",
    "    idio_vola = idio_vola.set_index('Date')\n",
    "    return idio_vola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun schreiben wir eine Funktion, die rollierende IVOLs für eine Vielzahl von Aktien berechnet. Das DataFrame `df_returns` muss herbei zwingend eine Spalte mit der Bezeichnung 'SP_Index' enthalten, in der die Indexrenditen stehen. In den übrigen Spalten stehen die Tagesrenditen unseres Anlageuniversums. \n",
    "\n",
    "Wir generieren durch den wiederholten Aufruf von `idiovola_single()` eine Liste `dfs`, die einspaltige DataFrames mit den jeweiligen IVOL Historien der Aktien enthält. Aus dieser Liste erzeugen wir das finale IVOL DataFrame `df_idiovola`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, the function for all stocks\n",
    "def df_idiovola(df_returns):\n",
    "    dfs = []\n",
    "    for column in df_returns.columns:\n",
    "        dfs.append(idiovola_single(df_returns[column], df_returns))\n",
    "\n",
    "    df_idiovola = pd.concat(dfs, axis=1).sort_index()    \n",
    "    df_idiovola.columns = df_returns.columns\n",
    "    df_idiovola.drop('SP_Index', axis=1, inplace=True)\n",
    "    return df_idiovola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen wir nun die Zeitreihe täglicher rollierender IVOLs für unser S&P500 Anlageuniversum für ein gleitendes Zeitfenster von 250 Handelstagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AES</th>\n",
       "      <th>AMG</th>\n",
       "      <th>...</th>\n",
       "      <th>WLTW</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.012580</td>\n",
       "      <td>0.035296</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.011642</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.008758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.013032</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.016213</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>0.008780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>0.007992</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.012548</td>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.008777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.013927</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.035581</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.006895</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.011704</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.008778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.035621</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.008785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ABT      ABBV      ABMD       ACN      ATVI      ADBE  \\\n",
       "Date                                                                     \n",
       "2018-01-02  0.007889  0.010438  0.013948  0.007202  0.017943  0.012580   \n",
       "2018-01-03  0.008003  0.010442  0.013915  0.007202  0.017936  0.012579   \n",
       "2018-01-04  0.007992  0.010448  0.013912  0.007141  0.017909  0.012548   \n",
       "2018-01-05  0.007869  0.010466  0.013927  0.007141  0.017939  0.012508   \n",
       "2018-01-08  0.007874  0.010471  0.013879  0.007121  0.017956  0.012503   \n",
       "\n",
       "                 AMD       AAP       AES       AMG  ...      WLTW      WYNN  \\\n",
       "Date                                                ...                       \n",
       "2018-01-02  0.035296  0.024660  0.013050  0.010132  ...  0.007843  0.016110   \n",
       "2018-01-03  0.035424  0.024952  0.013032  0.010187  ...  0.008065  0.016213   \n",
       "2018-01-04  0.035490  0.024955  0.013011  0.010199  ...  0.008090  0.016244   \n",
       "2018-01-05  0.035581  0.025043  0.012829  0.010297  ...  0.008099  0.016241   \n",
       "2018-01-08  0.035621  0.025045  0.012749  0.010214  ...  0.008095  0.016237   \n",
       "\n",
       "                 XEL       XRX      XLNX       XYL       YUM       ZBH  \\\n",
       "Date                                                                     \n",
       "2018-01-02  0.006841  0.011884  0.012397  0.009113  0.007934  0.011642   \n",
       "2018-01-03  0.006856  0.011713  0.012366  0.009132  0.007945  0.011709   \n",
       "2018-01-04  0.006874  0.011722  0.012369  0.009119  0.007952  0.011701   \n",
       "2018-01-05  0.006895  0.011673  0.012360  0.009090  0.007943  0.011704   \n",
       "2018-01-08  0.006843  0.011673  0.012648  0.009114  0.007937  0.011616   \n",
       "\n",
       "                ZION       ZTS  \n",
       "Date                            \n",
       "2018-01-02  0.012232  0.008758  \n",
       "2018-01-03  0.012272  0.008780  \n",
       "2018-01-04  0.012260  0.008777  \n",
       "2018-01-05  0.012261  0.008778  \n",
       "2018-01-08  0.012277  0.008785  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IVOL = df_idiovola(df_returns)\n",
    "IVOL.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementierung 1: gleichgewichtete Dezil-Portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst bringen wir die Aktien über die Methode `rank(axis=1, pct=True)` in eine Perzentil-Rankordnung gemäß der vergangenen IVOL. Aus den Perzentilen können wir Dezile generieren indem wir mit 10 multiplizieren (`mul(10)`) und dann auf die nächste ganze Zahl aufrunden (`np.ceil`). Wollen wir Aktien alternativ in Quintile sortieren, multiplizieren wir einfach mit 5 (`mul(5)`). **Wichtig:** durch die Festlegung `ascending=False` werden Aktien mit den höchsten (geringsten) IVOL in Gruppe 1 (10) sortiert. Äquivalent werden bei `ascending=True` die riskanten Aktien in Gruppe 10 und die risikoarmen Aktien in Gruppe 1 sortiert. \n",
    "\n",
    "Wir transformieren das DataFrame `rank_df` nun in ein DataFrame mit Positionsindikatoren: -1 für eine Short Position in Dezil 1 Aktien, 0 für eine Flat (d.h. keine) Position in Aktien der Dezile 2 bis 9, und 1 für eine Long Position in Dezil 10 Aktien. \n",
    "\n",
    "**Beachten Sie**: Da wir Long in Dezil 10 und Short in Dezil 1 gehen, implementieren wir durch die Wahl von `ascending=True` eine High-Risk Strategie, und durch `ascending=False` eine Low-Risk Strategie!\n",
    "\n",
    "Wir führen nun alles zusammen in der Funktion `weights_dc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'df_returns' = DataFrame with security daily returns and factor returns\n",
    "def weights_dc(df_returns):\n",
    "    stdev = df_idiovola(df_returns)\n",
    "    # Important: False = long in low IVOL stocks\n",
    "    rank_df = np.ceil(stdev.rank(axis=1, pct=True, ascending=True).mul(10))\n",
    "    for col in rank_df.columns:\n",
    "        rank_df[col] = np.where(rank_df[col]>9, 1, np.where(rank_df[col]<2, -1, 0))\n",
    "    \n",
    "    return rank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zudem definieren wir wieder unsere zwei **Lambda** Funktionen:\n",
    "    \n",
    "    1. \"compound\" berechnet aus dem Eingabe-Array x kumulative Mehr-Tagesrenditen;\n",
    "    2. \"daily_sr\" berechnet aus einem Array von Tagesrenditen die tägliche Sharpe-Ratio;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative returns\n",
    "compound = lambda x: (1 + x).prod() - 1\n",
    "\n",
    "# daily Sharpe Ratio\n",
    "daily_sr = lambda x: x.mean() / x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden berechnen wir zunächst für jeden Handelstag die nicht-normierten Aktiengewichte (-1: Short; 0: Flat; 1: Long) durch Anwendung unserer Funktion `weights_dc`. Das resultierende DataFrame nennen wir `port`. Dann legen wir die Anzahl der Handelstage (*hold*) fest, für die wir das Portfolio halten wollen ohne die Gewichte umzuschichten. \n",
    "\n",
    "Im letzten Schritt reduzieren wir die Zeitfrequenz von `port` auf die Länge (*hold*) der gewählten Portfoliohalteperiode, setzen die Gewichte auf die Werte die zu Beginn der Halteperiode gelten (über `.first()`), und wählen `.shift(1)`, da in t nur die Gewichte die zum Zeitpunkt t-1 bekannt sind implementiert werden können.  \n",
    "\n",
    "Dann berechnen wir die kumulativen Renditen jeder Aktie für die gewählte Portfoliohaltedauer. Hierzu verwenden wir die vorher definierte Lambda-Funktion `compound`.  \n",
    "\n",
    "Danach multiplizieren wir für jede der einzelnen Halteperioden die kumulativen Aktienrenditen mit den Positionsindikatoren (-1, 0, 1), summieren die Produkte über alle Aktien auf, und teilen durch die Summe aller offen (Long und Short) Positionen um eine gleichgewichtete Portfoliorendite zu bekommen. Die resultierende Zeitreihe der kumulativen Portfoliorenditen nennen wir `portf_rets`. Sie hat dieselbe Zeitfrequenz wie *freq*, die Portfoliohaltedauer in Anzahl Handelstage. Wenden wir unsere Lambda-Funktion `daily_sr`auf die Zeitreihe der Portfoliorenditen an und skalieren mit `np.sqrt(252/hold)` erhalten wir die annualisierte Sharpe-Ratio der Strategie. \n",
    "\n",
    "Lassen Sie uns nun die obigen Schritte in der Strategie-Funktion `strat_dc` zusammenfassen. Wir benötigen ein DataFrame (*df_returns*) mit den Renditezeitreihen unseres Anlageuniversums und der gewünschten Risikofaktoren zur Berechnung der IVOL, und die Länge der Portfoliohaltedauer (*hold*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy function\n",
    "def strat_dc(df_returns, hold):\n",
    "    # calculation of security weights: (-1: short, 0: no, 1: long)\n",
    "    freq = '%dB' % hold # holding period \n",
    "    port = weights_dc(df_returns) # security weights at business day freq\n",
    "       \n",
    "    # daily returns without index; adjustment if more than one index!\n",
    "    df_returns0 = df_returns.drop('SP_Index', axis=1)\n",
    "\n",
    "    # adjustment of frequency for returns and weight time series\n",
    "    temp0 = port.iloc[:, 0]\n",
    "    temp0.name = 'temp'\n",
    "    daily_rets = pd.merge(df_returns0, temp0, how='inner', on='Date').drop('temp', axis=1)\n",
    " \n",
    "    # calculation of portfolio returns\n",
    "    port = port.shift(1).resample(freq).first() # time series with 'freq' as frequency\n",
    "    returns = daily_rets.resample(freq).apply(compound)\n",
    "    portf = np.multiply(port, returns) # security returns * position direction (-1, 0, 1)\n",
    "    # summing position returns divided by number of positions\n",
    "    portf_rets = portf.sum(axis = 1)/(portf != 0).sum(axis =1)\n",
    "    \n",
    "    return daily_sr(portf_rets) * np.sqrt(252/hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen wir beispielhaft die Strategie als eine High-Risk Strategie (`ascending=True`) mit einer Halteperiode von 20 Handelstagen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4300863729003128"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_dc(df_returns, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementierung 2: Gewichte nach Frazzini and Pedersen (2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Implementierung der FP Gewichte erstellen wir das gewohnte (tägliche) DataFrame `ranks` mit den Perzentil-Rängen der Aktien gemäß ihrer IVOL über eine vergangene lookback (*window*) Periode. Daraus erstellen wir ein neues DataFrame `demeaned` mit Rangabweichungen indem wir jeweils den Zeilenmittelwert (`ranks.mean(axis=1)`) der Ränge vom Rang einer Aktie abziehen. Zusätzlich enthält das DataFrame `abs_demeaned` die absoluten Rangabweichungen. Wir bekommen die finalen FP Gewichte (DataFrame `weights`) indem wir die Zeilenwerte von `demeaned` durch die Hälfte der korrespondierenden Zeilensumme von `abs_demeaned` teilen. \n",
    "\n",
    "Fassen wir diese Schritte nun in der Gewichtsfunktion `weights_fp` zusammen. Alle weiteren Schritte erfolgen analog zur obigen Vorgehensweise. Die Strategiefunktion nenne ich `strat_fp`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_fp(df_returns):\n",
    "    # weights according to Frazzini and Pedersen (2014), equation (16), p. 9\n",
    "    stdev = df_idiovola(df_returns)\n",
    "    # percentile ranks; \"False\"= long in stocks with low IVOL!\n",
    "    ranks = stdev.rank(ascending=True, axis=1, pct=True) \n",
    "    demeaned = ranks.sub(ranks.mean(axis=1), axis='index') # cross-sectional demeaned\n",
    "    abs_demeaned = abs(demeaned) \n",
    "    # demeaned percentile ranks normalized by 0.5 * cross-sectional sum of abs. demeaned weights\n",
    "    weights = demeaned.div(0.5 * abs_demeaned.sum(axis=1), axis='index')\n",
    "    return weights\n",
    "\n",
    "\n",
    "# strategie returns (main function)\n",
    "def strat_fp(df_returns, hold):\n",
    "    # portfolio weights\n",
    "    freq = '%dB' % hold # holding period in number of business days\n",
    "    port = weights_fp(df_returns) # weights for each business day\n",
    "    \n",
    "    # daily returns without index; adjustment if more than one index!\n",
    "    df_returns0 = df_returns.drop('SP_Index', axis=1)\n",
    "\n",
    "    # adjustment of frequency for returns and weight time series\n",
    "    temp0 = port.iloc[:, 0]\n",
    "    temp0.name = 'temp'\n",
    "    daily_rets = pd.merge(df_returns0, temp0, how='inner', on='Date').drop('temp', axis=1)\n",
    "    \n",
    "    # strategy returns, shift(1) to adjust for implementation lag\n",
    "    port = port.shift(1).resample(freq).first() # time series with holding period freq\n",
    "    returns = daily_rets.resample(freq).apply(compound)\n",
    "    port_rets = (port * returns).sum(axis=1) # weighted sum of security returns \n",
    "    \n",
    "    return daily_sr(port_rets) * np.sqrt(252/hold)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen wir beispielhaft die Strategie als eine High-Risk Strategie (`ascending=True`) mit einer Halteperiode von 20 Handelstagen durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1792046276890964"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_fp(df_returns,20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
